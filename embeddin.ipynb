{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23897"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "text = []\n",
    "f = open('twitter.json')\n",
    "data = json.load(f)\n",
    "user = set()\n",
    "text = []\n",
    "for obj in data:\n",
    "    text.append(obj['text'])\n",
    "    if obj['author'] in user: continue\n",
    "    text.append(obj['raw_description'])\n",
    "    if obj['raw_description'] != obj['description']:\n",
    "        text.append(obj['description'])\n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dany/.local/share/virtualenvs/cuba-digital-lang-9Kd57kqM/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[#########################################################################]100%\n"
     ]
    }
   ],
   "source": [
    "from tokenizer_digital_language.custom_tokenizer import SpacyCustomTokenizer, get_progressbar\n",
    "\n",
    "_text = []\n",
    "vocabulary = set()\n",
    "nlp = SpacyCustomTokenizer()\n",
    "bar = get_progressbar(len(text))\n",
    "bar.start()\n",
    "for i, t in enumerate(text):\n",
    "    _text.append(set())\n",
    "    for token in nlp(t):\n",
    "        if token.is_stop: continue\n",
    "        word = token.text.lower() if token.lemma is None else token.lemma.lower()\n",
    "        vocabulary.add(word)\n",
    "        _text[-1].add(word)\n",
    "    bar.update(i + 1)\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31321\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(vocabulary))\n",
    "char_to_num = dict((c, i) for i , c in enumerate(chars))\n",
    "\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#########################################################################]100%\n"
     ]
    }
   ],
   "source": [
    "vector_text = []\n",
    "y_vector = []\n",
    "bar = get_progressbar(len(text))\n",
    "bar.start()\n",
    "for i, t in enumerate(_text):\n",
    "    y_vector.append([0] * len(_text))\n",
    "    y_vector[-1][i] = 1\n",
    "    vector_text.append([0] * len(vocabulary))\n",
    "    for word in t:\n",
    "        vector_text[-1][char_to_num[word]] = 1\n",
    "\n",
    "    bar.update(i + 1)\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:17:17.509659: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-30 22:17:17.510091: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(len(vocabulary), 20))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "import tensorflow as tf\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dense_repo):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.dense = tf.keras.layers.Dense(dense_repo)\n",
    "\n",
    "  def call(self, inputs, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "    return x\n",
    "\n",
    "model = MyModel(len(vocabulary), 20, 1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np   \n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "train_gen = DataGenerator(vector_text, y_vector, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in train_gen:\n",
    "    \n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    a= model.predict(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "    raise KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 31321, 1), dtype=float32, numpy=\n",
       "array([[[0.4862863],\n",
       "        [0.509598 ],\n",
       "        [0.509598 ],\n",
       "        ...,\n",
       "        [0.509598 ],\n",
       "        [0.509598 ],\n",
       "        [0.509598 ]],\n",
       "\n",
       "       [[0.4862863],\n",
       "        [0.509598 ],\n",
       "        [0.509598 ],\n",
       "        ...,\n",
       "        [0.509598 ],\n",
       "        [0.509598 ],\n",
       "        [0.509598 ]],\n",
       "\n",
       "       [[0.4862863],\n",
       "        [0.509598 ],\n",
       "        [0.509598 ],\n",
       "        ...,\n",
       "        [0.509598 ],\n",
       "        [0.509598 ],\n",
       "        [0.509598 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.4862863],\n",
       "        [0.509598 ],\n",
       "        [0.509598 ],\n",
       "        ...,\n",
       "        [0.509598 ],\n",
       "        [0.509598 ],\n",
       "        [0.509598 ]],\n",
       "\n",
       "       [[0.4862863],\n",
       "        [0.509598 ],\n",
       "        [0.509598 ],\n",
       "        ...,\n",
       "        [0.509598 ],\n",
       "        [0.509598 ],\n",
       "        [0.509598 ]],\n",
       "\n",
       "       [[0.4862863],\n",
       "        [0.509598 ],\n",
       "        [0.509598 ],\n",
       "        ...,\n",
       "        [0.509598 ],\n",
       "        [0.509598 ],\n",
       "        [0.509598 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "603d3262a7e4ed4b0851c01fdb7ddd10a0cced451adaee2bc5b3533b94fd096e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('cuba-digital-lang-9Kd57kqM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
